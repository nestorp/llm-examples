Sometime, the task we wish the model to perform is complicated, or we want to have the best performance possible. In these cases, fine-tuning the language model can result in improved performance.

As with inference, in order to use Llama 2 for fine-tuning, you'll need to have been granted access to the model both on Meta's platform and the HuggingFace Hub. The steps to acquire access are described in Section [[2. Setup]]. 

## 4.1. Fine-tuning Llama 2 for News Summarisation

The following notebook contains an example of supervised fine-tuning Llama 7b chat for a news summarisation task, using the CNN / DailyMail dataset. This dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarisation, though the original version was created for machine reading and comprehension and abstractive question answering.

Llama 7b is actually quite capable of producing summaries of these news articles without fine-tuning. However, the format it produces for these summaries does not exactly follow the one used in the dataset. You may run into a similar situation where you need the model to stick to a specific format in its output, and are unable to get it to do so through prompting only. This is when fine-tuning becomes necessary.

Since we are fine-tuning the Llama 2 chat model variant, we still need to use the prompt template with the special tokens described in Section [[3. Inference]]. To simplify this, an adapted version of the CNN / DailyMail dataset that has been created that has been modified to match this template. We also train on a sample of only 10% of the data, to keep training times reasonable. 

**Example Notebook**

[Fine-tuning Llama 2 with Transformers and TRL](https://colab.research.google.com/drive/1-l5GDH-7WjZ3eC3ZZhK13xnU8YfvUXwc?usp=drive_link)

## 4.2. Additional Resources
- [TRL Documentation](https://huggingface.co/docs/trl/index), the library we are using for fine-tuning.
- [Adapted CNN / DailyMail Dataset](https://huggingface.co/datasets/nespc/cnn_dailymail_prompts_10pct), our training dataset.
- [Llama-2-7b-chat-hf on Hugging Face Hub](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf), the model fine-tuned in the example notebook.
- [Illustrating Reinforcement Learning from Human Feedback (RLHF)](https://huggingface.co/blog/rlhf), a primer on Reinforcement Learning from Human Feedback, the approach commonly used to train chat models.
- [Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA](https://huggingface.co/blog/4bit-transformers-bitsandbytes), more information on quantization and LoRA, techniques for resource-efficient inference and fine-tuning.
- [LLaMA 2 - Every Resource you need](https://www.philschmid.de/llama-2), a compilation of relevant resources to learn about LLaMA 2 and how to get started quickly.