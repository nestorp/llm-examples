For many applications, generative LLMs can be applied directly through inference with no fine-tuning. In these cases, a clear formulation of the task is necessary, which is then communicated to the model through prompting. 

In order to use Llama 2 for inference, you'll need to have been granted access to the model both on Meta's platform and the HuggingFace Hub. The steps to acquire access are described in Section [[2. Setup]]. 
## 3.1. Sentiment analysis with Llama 2

The following notebook contains a demonstration of using Llama 2 to tackle a sentiment analysis task, using the IMDB dataset. The IMDB dataset is a widely-used resource in the field of Natural Language Processing (NLP) for sentiment analysis tasks. It contains 50,000 reviews from the Internet Movie Database (IMDB) that are labeled as either positive or negative, and thus a binary classification task.

The challenge in using a chat model for this task relies on ensuring that its outputs adhere to a binary format that can be used for automatic evaluation. This can be achieved through appropriate use of prompts. The notebook blow includes an example of how to prompt Llama 2 in order to have the model generate answers that stick to this binary format.

**Prompts and Special Tokens**

LLMs trained for chat are often trained to make use a system of different types of prompts that provide instructions that affect the model's outputs in different ways. This usually involves the use of a 'System Prompt', which affects the entirety of the conversation with the model and can be useful to influence aspects such as the model's writing style; and 'User Prompts', which are the instructions received from the user and receive replies from the model. The Llama 2 chat models have been trained with a set of special tokens that delimit the portions of the input that correspond to each of these prompt types. The template looks like this:

```
<s>[INST] <<SYS>>
{{ system_prompt }}
<</SYS>>

{{ user_message }} [/INST]
```

It's important to use these special tokens in order to take advantage of the models' pre-training. This can have a significant influence on performance. 

**Example Notebook**

[Inference with Transformers and Llama 2](https://colab.research.google.com/drive/17vcSeU8rgojhUyefzh_FiF5cmwDfvG50#scrollTo=yeCS6wNc6p5A)

## 3.2. Additional resources
- [IMFB Dataset on Hugging Face Hub](https://huggingface.co/datasets/imdb), the dataset used in this example.
- [Llama-2-7b-chat-hf on Hugging Face Hub](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf), the model used in this example.

